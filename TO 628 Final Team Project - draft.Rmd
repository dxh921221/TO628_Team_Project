
---
title: "TO 628 Final Team Project"
author: "Team 7: Xuhao Dai, Anubhav Gupta, Yongsoo Shin, Priti Singh, Brian Tsai"
date: "Due on April 20, 2020"
output:
  html_document:
    theme: spacelab
    highlight: tango
    toc: true
    number_sections: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
---

# Class Topics
So far, we have learned about the following topics. For this project, the following options will be pursued for modeling and detailed analysis.

  1. Linear Regression
  2. KNN
  3. ANN
  4. SVM
  5. Decision Trees
  6. Random Forest
  
# Motivation
Citi Bike is a bicycle sharing service in New York city operated by Motivate, an organization that manages some of the globe's largest bike networks in large cities. Because bikes must be picked up and dropped off at Citi Bike docking stations, people can easily take one-way trips and drop their bike off at 1 of 900 stations. 

With Citi Bikes being available 24 hours/day, 7 days/week, 365 days/year, NYC's enormous population, and variable weather, we believe there are insights to be gleaned from historical rider and local weather data. There are also opportunities for improving safety by sending notifications to riders' phones indicating riding conditions and availability.

This report will use Citi Bike rider and NYC weather data to predict daily customer behavior and describe the relative impact of different weather events on bike usage.

# Read Me
This document presents the group project for which city bike data in NYC is used. The purpose of this document is to share analysis of the influence of weather to the bike usage.

Here, city bike data from 2019 will be used for the analysis. Specifically, 5% of the entire 2019 data was extracted, and the extracted data was categorized into average ride usage per day (365 days in total). Thereafter, the yearly usage data was randomly divided into train (80%, 292 days) and test (20%, 73 days) for the modeling, testing the accuracy of the models, and business analytics. 

Ultimately, the findings will be used to identify the relationship between weather and bike usage and predict the bike usage based on chosen parameters (e.g. precipitation amount). Thereafter, some insights will be presented for the bike business.

Note that there was an effort to retrieve station capacity information into the dataset. However, it was not pursued as only 20% of the stations in the dataset were identified with the capacity.

# Dataset Explanation
  - City bike data in NYC
  - Each dataset is comprised of 1 month trip data
    - Data from 12 months of 2019 have been combined and divided into train (80%) and test (20%) datasets.
  - Variables (City bike):
    - trip duration (sec)
    - start time (year, month, day, time)
    - stop time (year, month, day, time)
    - start station (id, lat/long)
    - end station (id, lat/long)
    - bike id
    - user type
      - customer (24 hr vs 3 day)
      - subscriber (annual)
    - birth year
    - gender (0, 1, 2 = unknown, male, female)
    - trip distance (based on the lat/long, trip distance was calculated with r package haversine)
    - trip speed (based on trip distance, trip speed was calculated with trip duration)
    - total # bike rentals (per day)
  - Variables (Weather):
    - TMIN (minimum temperature in C)
    - TMAX (maximum temperature in C)
    - Average wind speed
    - PRCP (mm)
    - SNOW (mm)

# Data Collection And Preparation 
NOTE: Due to extreme large raw data set size, a separate RMD is used to process raw data and generate the dataset used for all analysis in this RMD report.  

## Citi Bike Data
The raw Citi bike 2019 usage dataset is obtained from the website "https://s3.amazonaws.com/tripdata/index.html". All 12 months of data in 2019 is combined first. Due to the extreme large data size (over 22 million rows), a sample size of 5% of the raw dataset is generated using set.seed() function resulting in over 1 million rows of data. Then a few data cleaning processes were completed: 

  1. Extract year, month, day, hour and minute from the column "Date" which contains time information all in one cell which is hard to be used for further analysis. 
  2. Rows with birth year before 1920 are converted to the median of the whole dataset. The team assumed people over 100 years old might not be able to ride bikes and it was just a joke from people who filled the survey. 
  3. Rows with trip duration above the 99.9 percentile is removed. Some outliers were noticed such as a trip with 3 million seconds. These outliers would skew the analysis and modeling. Therefore, the team decided to remove them. 

## Weather Data 
The raw NYC weather data is obtained from NOAA website through Python API. The year, month, day, hour and minute information are extracted from the "Date" column. 

## Data Merging 
The bike data and weather data were merged using the year, month and day as the relational keys. The final combined dataset were then separated into train (80%) and test (20%) dataset and stored in files "train_final.csv" and "test_final.csv". The team didn't realize that train/test separation should not have been completed in such an early stage until later in the process. However, it was very time consuming to go through everything discussed above just for a combined 5% dataset. Therefore, the team decided to just aggregate both "train_final.csv" and "test_final.csv" at the beginning of further analysis which is much less time consuming. 


# Load Datasets
```{r}
#load train dataset
traindata = read.csv("train_final.csv")

#load test dataset
testdata = read.csv("test_final.csv")

```

# Clean up Datasets
Ensure that no additional clean up is needed after train and test datasets are extracted from the entire 2019 usage.
```{r}

#train dataset
traindata$X = NULL
traindata$Date = NULL
traindata$start_station_id = as.integer(traindata$start_station_id)
colnames(traindata)
str(traindata)
summary(traindata)


#test dataset
testdata$X = NULL
testdata$Date = NULL
testdata$start_station_id = as.integer(testdata$start_station_id)
colnames(testdata)
str(testdata)
summary(testdata)

```

# Further Data Exploration
Trip duration is heavily skewed to left although there are decent amount of outliers in the upper end. Note that the extreme 0.5% was removed (e.g. trip duration of 1+ day).

User group appears to be mainly from adult (20-44) and middle age (45-64).

User type turns out to have very high ratio of subscriber.
```{r}

#1. trip duration
boxplot(traindata$avg_trip_duration, main = "trip duration (sec)")
hist(traindata$avg_trip_duration, main = "trip duration (sec)")

#5. birth year
summary(traindata$age_group)

#6. user type
summary(traindata$usertype)

```

# Data Preparation for Modeling
Data has been reorganized to split the data per each day. Information about start day and end day are treated separately. The information of interest are: average birth year, average trip duration, and total check-ins/check-outs per given day.

```{r}
# Look for and download plyr package if it does not already exist
if (!require("plyr")) {
  install.packages("plyr")
}
#read in plyr package
library(plyr)

#organize data per day (avg trip duration, avg speed per day, total check out per day, avg travel distance per day)
train_per_day = ddply(traindata,.(start_month,start_day, avg_wind_speed, TMIN, TMAX, PRCP, SNOW), c(function(x) mean(x$avg_trip_duration), function(x) mean(x$avg_speed), function(x) sum(x$frequency)))
colnames(train_per_day) = c("start_month","start_day","avg_wind_speed","TMIN","TMAX","PRCP","SNOW","avg_trip_duration","avg_speed","frequency")

test_per_day = ddply(testdata,.(start_month,start_day, avg_wind_speed, TMIN, TMAX, PRCP, SNOW), c(function(x) mean(x$avg_trip_duration), function(x) mean(x$avg_speed), function(x) sum(x$frequency)))
colnames(test_per_day) = c("start_month","start_day","avg_wind_speed","TMIN","TMAX","PRCP","SNOW","avg_trip_duration","avg_speed","frequency")

head(train_per_day)
summary(train_per_day)
head(test_per_day)
summary(test_per_day)
```

# Modeling

  1. Topics to be used
    1. Linear Regression
    3. KNN
    4. ANN
    5. SVM
    6. Decision Trees
    7. Random Forest
  2. Modeling
    1. avg trip duration per day
    2. avg speed per day
    3. total check outs per day
    4. avg travel distance per day

## Avg trip duration per day

### Linear model
```{r}
#model

trip_duration_linear <- lm(avg_trip_duration ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)

summary(trip_duration_linear)

#predict
trip_duration_pred_linear <- predict(trip_duration_linear, test_per_day) 

#compare
plot(trip_duration_pred_linear, test_per_day$avg_trip_duration, main = "Linear model Prediction Assessmen",
     xlab = "predicted" , ylab = "actual")
abline(a = 0, b = 1, col = "red")


#compute prediction accuracy with threshold of 10%
trip_duration_accuracy_linear = ifelse(abs(trip_duration_pred_linear - test_per_day$avg_trip_duration)/test_per_day$avg_trip_duration > 0.10, 0, 1)

trip_duration_accuracy_linear

```

### Linear Model - Interaction
For interaction, look at significant factors from simple linear regression
```{r}

#model
trip_duration_linear_interaction = lm(avg_trip_duration ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW + TMAX*PRCP , data = train_per_day)

summary(trip_duration_linear_interaction)

```


### KNN
```{r}

#load library
library(class)

#model
train_labels = train_per_day$avg_trip_duration
test_labels = test_per_day$avg_trip_duration

#predict
trip_duration_pred_knn = knn(train = train_per_day, test = test_per_day, cl = train_labels, k = 17) #sqrt(sample size) is a rule of thumb

#compare
plot((as.numeric(levels(trip_duration_pred_knn))[trip_duration_pred_knn]), test_per_day$avg_trip_duration, main = "KNN model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
trip_duration_accuracy_knn = ifelse(abs((as.numeric(levels(trip_duration_pred_knn))[trip_duration_pred_knn]) - test_per_day$avg_trip_duration)/test_per_day$avg_trip_duration > 0.10, 0, 1)

```
### ANN
```{r}

#load library
library(neuralnet)

#model
trip_duration_model_ann = neuralnet(formula = avg_trip_duration ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day, hidden = 3)

#predict
trip_duration_pred_ann = compute(trip_duration_model_ann, test_per_day)
trip_duration_pred_ann_result = trip_duration_pred_ann$net.result

#compare
plot(trip_duration_pred_ann_result, test_per_day$avg_trip_duration, main = "ANN model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
trip_duration_accuracy_ann = ifelse(abs(trip_duration_pred_ann_result - test_per_day$avg_trip_duration)/test_per_day$avg_trip_duration > 0.10, 0, 1)

```

### SVM
```{r}

#load library
library(kernlab)

#model
trip_duration_model_svm = ksvm(avg_trip_duration ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day, kernel = "vanilladot")
  
#predict
trip_duration_pred_svm = predict(trip_duration_model_svm, test_per_day)

#compare
plot(trip_duration_pred_svm, test_per_day$avg_trip_duration, main = "SVM model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
trip_duration_accuracy_svm = ifelse(abs(trip_duration_pred_svm - test_per_day$avg_trip_duration)/test_per_day$avg_trip_duration > 0.10, 0, 1)
```

### Decision Trees
```{r}

#load library
library(C50)

#model
trip_duration_model_dt = C5.0(as.factor(avg_trip_duration) ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)
  
#predict
trip_duration_pred_dt = predict(trip_duration_model_dt, test_per_day)

#compare
plot((as.numeric(levels(trip_duration_pred_dt))[trip_duration_pred_dt]), test_per_day$avg_trip_duration, main = "Decision Tree model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
trip_duration_accuracy_dt = ifelse(abs((as.numeric(levels(trip_duration_pred_dt))[trip_duration_pred_dt]) - test_per_day$avg_trip_duration)/test_per_day$avg_trip_duration > 0.10, 0, 1)

```

### Random Forest
```{r}
#load library
library(randomForest)

#model
set.seed(12345)
trip_duration_model_rf = randomForest(as.factor(avg_trip_duration) ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)
  
#predict
trip_duration_pred_rf = predict(trip_duration_model_rf, test_per_day)

#compare
plot((as.numeric(levels(trip_duration_pred_rf))[trip_duration_pred_rf]), test_per_day$avg_trip_duration, main = "Random Forest model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
trip_duration_accuracy_rf = ifelse(abs((as.numeric(levels(trip_duration_pred_rf))[trip_duration_pred_rf]) - test_per_day$avg_trip_duration)/test_per_day$avg_trip_duration > 0.10, 0, 1)

```
### Assess Models
```{r}
trip_duration_model_comparison = matrix(0, nrow=6, ncol=3)
colnames(trip_duration_model_comparison) = c("bad_prediction","good_prediction", "accuracy")
rownames(trip_duration_model_comparison) = c("linear","knn","ann","svm","decision_tree","random_forest")

trip_duration_model_comparison[1,] = c((length(trip_duration_accuracy_linear)-sum(trip_duration_accuracy_linear)), sum(trip_duration_accuracy_linear), round(sum(trip_duration_accuracy_linear)/length(trip_duration_accuracy_linear),3))
trip_duration_model_comparison[2,] = c((length(trip_duration_accuracy_knn)-sum(trip_duration_accuracy_knn)), sum(trip_duration_accuracy_knn), round(sum(trip_duration_accuracy_knn)/length(trip_duration_accuracy_knn),3))
trip_duration_model_comparison[3,] = c((length(trip_duration_accuracy_ann)-sum(trip_duration_accuracy_ann)), sum(trip_duration_accuracy_ann), round(sum(trip_duration_accuracy_ann)/length(trip_duration_accuracy_ann),3))
trip_duration_model_comparison[4,] = c((length(trip_duration_accuracy_svm)-sum(trip_duration_accuracy_svm)), sum(trip_duration_accuracy_svm), round(sum(trip_duration_accuracy_svm)/length(trip_duration_accuracy_svm),3))
trip_duration_model_comparison[5,] = c((length(trip_duration_accuracy_dt)-sum(trip_duration_accuracy_dt)), sum(trip_duration_accuracy_dt), round(sum(trip_duration_accuracy_dt)/length(trip_duration_accuracy_dt),3))
trip_duration_model_comparison[6,] = c((length(trip_duration_accuracy_rf)-sum(trip_duration_accuracy_rf)), sum(trip_duration_accuracy_rf), round(sum(trip_duration_accuracy_rf)/length(trip_duration_accuracy_rf),3))

```

### Findings

Based on the different models assessed, SVM gave the best prediction of average trip duration with the accuracy of ~79.5%. This is considering that the results are accurate if lying within 10% range of the actual trip duration value.

From the linear model, it can be concluded that there is a relationship between average trip duration and different weather parameters. For example, it was found that TMAX had a positive relationship and PRCP had a negative relationship with average trip duration. From this, it can be concluded that warmer days have longer rides and rainy days have shorter rides in general.

Additionally, it was found that start month is negatively related to the average bike speed. This finding can be correlated with the weather-related finding noted above in a way that higher month (colder weather) results in faster bike speed.

There was no significant impact of variables TMIN, SNOW, start_month, and start_day. This indicates that the trip duration is not impacted by lower temperatures, snow amount, and trip month or day. 

```{r}

trip_duration_model_comparison

```


## Avg speed per day
### Linear Model
```{r}

#model
speed_model_linear = lm(avg_speed ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)

summary(speed_model_linear)

#predict
speed_pred_linear = predict(speed_model_linear, newdata = test_per_day)

#compare
plot(speed_pred_linear, test_per_day$avg_speed, main = "Linear model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
speed_accuracy_linear = ifelse(abs(speed_pred_linear - test_per_day$avg_speed)/test_per_day$avg_speed > 0.10, 0, 1)

```

### Linear Model - Interaction
For interaction, look at significant factors from simple linear regression
```{r}

#model
speed_model_linear_interaction = lm(avg_speed ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW + start_month * avg_wind_speed + start_month * TMAX + start_month * PRCP + avg_wind_speed * TMAX + avg_wind_speed * PRCP + TMAX * PRCP, data = train_per_day)

summary(speed_model_linear_interaction)

```

### KNN
```{r}

#load library
library(class)

#model
train_labels = train_per_day$avg_speed
test_labels = test_per_day$avg_speed

#predict
speed_pred_knn = knn(train = train_per_day, test = test_per_day, cl = train_labels, k = 17) #sqrt(sample size) is a rule of thumb

#compare
plot((as.numeric(levels(speed_pred_knn))[speed_pred_knn]), test_per_day$avg_speed, main = "KNN model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
speed_accuracy_knn = ifelse(abs((as.numeric(levels(speed_pred_knn))[speed_pred_knn]) - test_per_day$avg_speed)/test_per_day$avg_speed > 0.10, 0, 1)

```

### ANN
```{r}

#load library
library(neuralnet)

#model
speed_model_ann = neuralnet(formula = avg_speed ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day, hidden = 3)

#predict
speed_pred_ann = compute(speed_model_ann, test_per_day)
speed_pred_ann_result = speed_pred_ann$net.result

#compare
plot(speed_pred_ann_result, test_per_day$avg_speed, main = "ANN model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
speed_accuracy_ann = ifelse(abs(speed_pred_ann_result - test_per_day$avg_speed)/test_per_day$avg_speed > 0.10, 0, 1)

```

### SVM
```{r}

#load library
library(kernlab)

#model
speed_model_svm = ksvm(avg_speed ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day, kernel = "vanilladot")
  
#predict
speed_pred_svm = predict(speed_model_svm, test_per_day)

#compare
plot(speed_pred_svm, test_per_day$avg_speed, main = "SVM model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
speed_accuracy_svm = ifelse(abs(speed_pred_svm - test_per_day$avg_speed)/test_per_day$avg_speed > 0.10, 0, 1)
```

### Decision Trees
```{r}

#load library
library(C50)

#model
speed_model_dt = C5.0(as.factor(avg_speed) ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)
  
#predict
speed_pred_dt = predict(speed_model_dt, test_per_day)

#compare
plot((as.numeric(levels(speed_pred_dt))[speed_pred_dt]), test_per_day$avg_speed, main = "Decision Tree model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
speed_accuracy_dt = ifelse(abs((as.numeric(levels(speed_pred_dt))[speed_pred_dt]) - test_per_day$avg_speed)/test_per_day$avg_speed > 0.10, 0, 1)

```

### Random Forest
```{r}
#load library
library(randomForest)

#model
set.seed(12345)
speed_model_rf = randomForest(as.factor(avg_speed) ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)
  
#predict
speed_pred_rf = predict(speed_model_rf, test_per_day)

#compare
plot((as.numeric(levels(speed_pred_rf))[speed_pred_rf]), test_per_day$avg_speed, main = "Random Forest model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")

#compute prediction accuracy with threshold of 10%
speed_accuracy_rf = ifelse(abs((as.numeric(levels(speed_pred_rf))[speed_pred_rf]) - test_per_day$avg_speed)/test_per_day$avg_speed > 0.10, 0, 1)

```

### Assess Models
```{r}
speed_model_comparison = matrix(0, nrow=6, ncol=3)
colnames(speed_model_comparison) = c("bad_prediction","good_prediction", "accuracy")
rownames(speed_model_comparison) = c("linear","knn","ann","svm","decision_tree","random_forest")

speed_model_comparison[1,] = c((length(speed_accuracy_linear)-sum(speed_accuracy_linear)), sum(speed_accuracy_linear), round(sum(speed_accuracy_linear)/length(speed_accuracy_linear),3))
speed_model_comparison[2,] = c((length(speed_accuracy_knn)-sum(speed_accuracy_knn)), sum(speed_accuracy_knn), round(sum(speed_accuracy_knn)/length(speed_accuracy_knn),3))
speed_model_comparison[3,] = c((length(speed_accuracy_ann)-sum(speed_accuracy_ann)), sum(speed_accuracy_ann), round(sum(speed_accuracy_ann)/length(speed_accuracy_ann),3))
speed_model_comparison[4,] = c((length(speed_accuracy_svm)-sum(speed_accuracy_svm)), sum(speed_accuracy_svm), round(sum(speed_accuracy_svm)/length(speed_accuracy_svm),3))
speed_model_comparison[5,] = c((length(speed_accuracy_dt)-sum(speed_accuracy_dt)), sum(speed_accuracy_dt), round(sum(speed_accuracy_dt)/length(speed_accuracy_dt),3))
speed_model_comparison[6,] = c((length(speed_accuracy_rf)-sum(speed_accuracy_rf)), sum(speed_accuracy_rf), round(sum(speed_accuracy_rf)/length(speed_accuracy_rf),3))

```

### Findings
It turns out that knn is best at predicting the average speed with the accuracy of ~95%. 

From the linear model, it can be concluded that there is a relationship between average bike speed and weather parameters. For example, it was found that wind speed/TMAX had negative relationship and PRCP had positive relationship with average bike speed. From this, it can be concluded that worse weather results in faster bike speed. Also, among significant factors from simple linear regression model, it was found that there is a negative interaction between average wind speed and TMAX (higher temperature, lower wind speed).

Additionally, it was found that start month is negatively related to the average bike speed. This finding can be correlated with the weather-related finding noted above in a way that higher month (colder weather) results in faster bike speed.

```{r}
speed_model_comparison
```

## Total check outs per day
### Linear Model
```{r}
frequency_linear <- lm(frequency ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)

summary(frequency_linear)

#predict
frequency_pred_linear <- predict(frequency_linear, test_per_day) 

#compare
plot(frequency_pred_linear, test_per_day$frequency, main = "Linear model Prediction Assessmen",
     xlab = "predicted" , ylab = "actual")
abline(a = 0, b = 1, col = "red")


#compute prediction accuracy with threshold of 10%
frequency_accuracy_linear = ifelse(abs(frequency_pred_linear - test_per_day$frequency)/test_per_day$frequency > 0.10, 0, 1)
```

### KNN
```{r}
#load library
library(class)
#model
train_labels = train_per_day$frequency
test_labels = test_per_day$frequency
#predict
frequency_pred_knn = knn(train = train_per_day, test = test_per_day, cl = train_labels, k = 17) #sqrt(sample size) is a rule of thumb
#compare
plot((as.numeric(levels(frequency_pred_knn))[frequency_pred_knn]), test_per_day$frequency, main = "KNN model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
frequency_accuracy_knn = ifelse(abs((as.numeric(levels(frequency_pred_knn))[frequency_pred_knn]) - test_per_day$frequency)/test_per_day$frequency > 0.10, 0, 1)

```

### ANN
```{r}
#load library
library(neuralnet)
#model
frequency_model_ann = neuralnet(formula = frequency ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day, hidden = 3)
#predict
frequency_pred_ann = compute(frequency_model_ann, test_per_day)
frequency_pred_ann_result = frequency_pred_ann$net.result
#compare
plot(frequency_pred_ann_result, test_per_day$frequency, main = "ANN model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
frequency_accuracy_ann = ifelse(abs(frequency_pred_ann_result - test_per_day$frequency)/test_per_day$frequency > 0.10, 0, 1)
```

### SVM
```{r}
#load library
library(kernlab)
#model
frequency_model_svm = ksvm(frequency ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day, kernel = "vanilladot")
  
#predict
frequency_pred_svm = predict(frequency_model_svm, test_per_day)
#compare
plot(frequency_pred_svm, test_per_day$frequency, main = "SVM model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
frequency_accuracy_svm = ifelse(abs(frequency_pred_svm - test_per_day$frequency)/test_per_day$frequency > 0.10, 0, 1)
```


### Decision Trees
```{r}
#load library
library(C50)
#model
frequency_model_dt = C5.0(as.factor(frequency) ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)
  
#predict
frequency_pred_dt = predict(frequency_model_dt, test_per_day)
#compare
plot((as.numeric(levels(frequency_pred_dt))[frequency_pred_dt]), test_per_day$frequency, main = "Decision Tree model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
frequency_accuracy_dt = ifelse(abs((as.numeric(levels(frequency_pred_dt))[frequency_pred_dt]) - test_per_day$frequency)/test_per_day$frequency > 0.10, 0, 1)
```

### Random Forest
```{r}
#load library
library(randomForest)
#model
set.seed(12345)
frequency_model_rf = randomForest(as.factor(frequency) ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)
  
#predict
frequency_pred_rf = predict(frequency_model_rf, test_per_day)
#compare
plot((as.numeric(levels(frequency_pred_rf))[frequency_pred_rf]), test_per_day$frequency, main = "Random Forest model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
frequency_accuracy_rf = ifelse(abs((as.numeric(levels(frequency_pred_rf))[frequency_pred_rf]) - test_per_day$frequency)/test_per_day$frequency > 0.10, 0, 1)
```

### Assess Models
```{r}
frequency_model_comparison = matrix(0, nrow=6, ncol=3)
colnames(frequency_model_comparison) = c("bad_prediction","good_prediction", "accuracy")
rownames(frequency_model_comparison) = c("linear","knn","ann","svm","decision_tree","random_forest")
frequency_model_comparison[1,] = c((length(frequency_accuracy_linear)-sum(frequency_accuracy_linear)), sum(frequency_accuracy_linear), round(sum(frequency_accuracy_linear)/length(frequency_accuracy_linear),3))
frequency_model_comparison[2,] = c((length(frequency_accuracy_knn)-sum(frequency_accuracy_knn)), sum(frequency_accuracy_knn), round(sum(frequency_accuracy_knn)/length(frequency_accuracy_knn),3))
frequency_model_comparison[3,] = c((length(frequency_accuracy_ann)-sum(frequency_accuracy_ann)), sum(frequency_accuracy_ann), round(sum(frequency_accuracy_ann)/length(frequency_accuracy_ann),3))
frequency_model_comparison[4,] = c((length(frequency_accuracy_svm)-sum(frequency_accuracy_svm)), sum(frequency_accuracy_svm), round(sum(frequency_accuracy_svm)/length(frequency_accuracy_svm),3))
frequency_model_comparison[5,] = c((length(frequency_accuracy_dt)-sum(frequency_accuracy_dt)), sum(frequency_accuracy_dt), round(sum(frequency_accuracy_dt)/length(frequency_accuracy_dt),3))
frequency_model_comparison[6,] = c((length(frequency_accuracy_rf)-sum(frequency_accuracy_rf)), sum(frequency_accuracy_rf), round(sum(frequency_accuracy_rf)/length(frequency_accuracy_rf),3))
```

### Findings

From the results shown below, knn has the best accuracy for predicting check-outs with the accuracy of 0.945. 

In addition, based on the linear model analysis, it shows that there is a relationship between check-outs amount and weather parameters. From the analysis, it appears that TMAX has a positive relationship with amount of check-outs while PRCP has a negative relationship. 


```{r}
frequency_model_comparison
```



## Avg travel distance per day
```{r}
# Calculating average travel distance
train_per_day$avg_distance <- train_per_day$avg_speed * train_per_day$avg_trip_duration
test_per_day$avg_distance <- test_per_day$avg_speed * test_per_day$avg_trip_duration
```

### Linear model
```{r}
#model
distance_linear <- lm(avg_distance ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)
summary(distance_linear)
#predict
distance_pred_linear <- predict(distance_linear, test_per_day) 
#compare
plot(distance_pred_linear, test_per_day$avg_distance, main = "Linear Model For Distance",
     xlab = "predicted" , ylab = "actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
distance_accuracy_linear = ifelse(abs(distance_pred_linear - test_per_day$avg_distance)/test_per_day$avg_distance > 0.10, 0, 1)
distance_accuracy_linear
```

### KNN
```{r}
#load library
library(class)
#model
train_labels = train_per_day$avg_distance
test_labels = test_per_day$avg_distance
#predict
distance_pred_knn = knn(train = train_per_day, test = test_per_day, cl = train_labels, k = 17) #sqrt(sample size) is a rule of thumb
#compare
plot((as.numeric(levels(distance_pred_knn))[distance_pred_knn]), test_per_day$avg_distance, main = "KNN model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
distance_accuracy_knn = ifelse(abs((as.numeric(levels(distance_pred_knn))[distance_pred_knn]) - test_per_day$avg_distance)/test_per_day$avg_distance > 0.10, 0, 1)
```
### ANN
```{r}
#load library
library(neuralnet)
#model
distance_model_ann = neuralnet(formula = avg_distance ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day, hidden = 3)
#predict
distance_pred_ann = compute(distance_model_ann, test_per_day)
distance_pred_ann_result = distance_pred_ann$net.result
#compare
plot(distance_pred_ann_result, test_per_day$avg_distance, main = "ANN model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
distance_accuracy_ann = ifelse(abs(distance_pred_ann_result - test_per_day$avg_distance)/test_per_day$avg_distance > 0.10, 0, 1)
```

### SVM
```{r}
#load library
library(kernlab)
#model
distance_model_svm = ksvm(avg_distance ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day, kernel = "vanilladot")
  
#predict
distance_pred_svm = predict(distance_model_svm, test_per_day)
#compare
plot(distance_pred_svm, test_per_day$avg_distance, main = "SVM model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
distance_accuracy_svm = ifelse(abs(distance_pred_svm - test_per_day$avg_distance)/test_per_day$avg_distance > 0.10, 0, 1)
```

### Decision Trees
```{r}
#load library
library(C50)
#model
distance_model_dt = C5.0(as.factor(avg_distance) ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)
  
#predict
distance_pred_dt = predict(distance_model_dt, test_per_day)
#compare
plot((as.numeric(levels(distance_pred_dt))[distance_pred_dt]), test_per_day$avg_distance, main = "Decision Tree model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
distance_accuracy_dt = ifelse(abs((as.numeric(levels(distance_pred_dt))[distance_pred_dt]) - test_per_day$avg_distance)/test_per_day$avg_distance > 0.10, 0, 1)
```

### Random Forest
```{r}
#load library
library(randomForest)
#model
set.seed(12345)
distance_model_rf = randomForest(as.factor(avg_distance) ~ start_month + start_day + avg_wind_speed + TMIN + TMAX + PRCP + SNOW, data = train_per_day)
  
#predict
distance_pred_rf = predict(distance_model_rf, test_per_day)
#compare
plot((as.numeric(levels(distance_pred_rf))[distance_pred_rf]), test_per_day$avg_distance, main = "Random Forest model Prediction Assessment", xlab="predicted", ylab="actual")
abline(a = 0, b = 1, col = "red")
#compute prediction accuracy with threshold of 10%
distance_accuracy_rf = ifelse(abs((as.numeric(levels(distance_pred_rf))[distance_pred_rf]) - test_per_day$avg_distance)/test_per_day$avg_distance > 0.10, 0, 1)
```
### Assess Models
```{r}
distance_model_comparison = matrix(0, nrow=6, ncol=3)
colnames(distance_model_comparison) = c("bad_prediction","good_prediction", "accuracy")
rownames(distance_model_comparison) = c("linear","knn","ann","svm","decision_tree","random_forest")
distance_model_comparison[1,] = c((length(distance_accuracy_linear)-sum(distance_accuracy_linear)), sum(distance_accuracy_linear), round(sum(distance_accuracy_linear)/length(distance_accuracy_linear),3))
distance_model_comparison[2,] = c((length(distance_accuracy_knn)-sum(distance_accuracy_knn)), sum(distance_accuracy_knn), round(sum(distance_accuracy_knn)/length(distance_accuracy_knn),3))
distance_model_comparison[3,] = c((length(distance_accuracy_ann)-sum(distance_accuracy_ann)), sum(distance_accuracy_ann), round(sum(distance_accuracy_ann)/length(distance_accuracy_ann),3))
distance_model_comparison[4,] = c((length(distance_accuracy_svm)-sum(distance_accuracy_svm)), sum(distance_accuracy_svm), round(sum(distance_accuracy_svm)/length(distance_accuracy_svm),3))
distance_model_comparison[5,] = c((length(distance_accuracy_dt)-sum(distance_accuracy_dt)), sum(distance_accuracy_dt), round(sum(distance_accuracy_dt)/length(distance_accuracy_dt),3))
distance_model_comparison[6,] = c((length(distance_accuracy_rf)-sum(distance_accuracy_rf)), sum(distance_accuracy_rf), round(sum(distance_accuracy_rf)/length(distance_accuracy_rf),3))
```

### Findings
As with previous results, KNN was the best model with a prediction accuracy of ~97% with an error threshold of 10%.

The linear model shows notable linkages between average distance travelled in a day and start month, maximum temperature, and precipitation.

Ride distances increased precipitously with increase in max daily temperature, dropped with an increase in precipitation, and decreased with increasing calendar months. It is curious to note that through the course of a calendar year, ride distances decreased. One would expect distance to increase from January (winter weather) to July (summer weather) and subsequently decrease through December (return to winter weather).

Because of the inherent seasonality and human factors involved with the data, a linear regression paints a rough picture but other models such as KNN provide more accurate predictions.

```{r}
distance_model_comparison
```


# Conclusion
We used various regression and machine learning algorithms in the R programming language to predict Citi Bike usage data based on the weather information in NYC. Using 2019 data for both training and testing, KNN consistently provided the highest accuracy models considering a 10% error buffer.

Average trip duration, trip distance, and the total number of checkouts per day were positively correlated with increasing TMAX and negatively with PRCP. This is a reasonable outcome as people would generally be inclined to cycle more and longer in warmer weather with less precipitation. 

Intriguingly, people tended to cycle faster on colder days with more precipitation. This would indicate people wanted to escape the elements and reach their destination quicker. Faster cycling in inclement weather such as rainfall could result in safety incidents so we recommend Citi Bike pushes weather alerts to its riders when weather forecasts call for colder than normal days or increased precipitation. We also recommend Citi Bike assesses the decrease in bike usage through a calendar year as weather may not be the only factor impacting it.



